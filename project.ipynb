{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train.csv')\n",
    "train_ans = pd.read_csv('./train_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ans = train_ans.iloc[:,1]\n",
    "y = np.repeat(train_ans.to_numpy(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll test out classic stochastic gradient descent classification on the first ~40 features. These features are **tortuousity**, which describes the \"twistedness\" of the handwriting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tort_data = train_data.iloc[:, 4:44]\n",
    "\n",
    "x = train_tort_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1128, 40)\n",
      "(1128,)\n",
      "\n",
      "There are 572 male writers.\n",
      "\n",
      "There are 556 male writers.\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x))\n",
    "print(np.shape(y))\n",
    "\n",
    "print(f'\\nThere are {(y==0).sum()} male writers.')\n",
    "print(f'\\nThere are {(y==1).sum()} male writers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDClassifier()\n",
    "model.fit(X=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = model.predict(X=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print((answers != y).sum())\n",
    "print(answers[:32])\n",
    "print(y[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get 61% accuracy (439 misclassifications over 1128 samples). We also print the first 32 predicted answers, and their corresponding ground truths. This result is alright, but we decided to try to use other features to try and achieve a better result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we attempted to use the next 855 features, describing the **curviness** of the handwriting. We wanted to test which descriptor of handwriting was accurate when it came to accurately classifying the gender of the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_curve_data = train_data.iloc[:, 54:900]\n",
    "x = train_curve_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1128, 846)\n",
      "(1128,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = model.predict(X=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print((answers != y).sum())\n",
    "print(answers[:32])\n",
    "print(y[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we got very similar results to our attempt of SGD with tortuousity features. We wanted to give one other set of features a try before writing off SGD entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next ~4000 features are called \"chaincode\". We weren't sure what that meant, but we inferred that it referred to how letters connected to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chain_data = train_data.iloc[:, 901:5020]\n",
    "x = train_chain_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1128, 4119)\n",
      "(1128,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = model.predict(X=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "0.648936170212766\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print((answers != y).sum())\n",
    "print(model.score(X=x, y=y))\n",
    "print(answers[:32])\n",
    "print(y[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our results were much worse than the previous two feature sets, however, there was a lot of variance every time we ran classification, so we chalked it up to SGD being a poor fit for this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we tried to use **Random Forest** classification. We felt like this would be a good use case because of its similarity to traditional Decision Tree methods. In addition, to keep track of potential overfitting, we also implemented cross validation on the training set, using a 25/75 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chain_data = train_data.iloc[:, 901:5020]\n",
    "x = train_chain_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=250, min_samples_leaf=3)\n",
    "model.fit(X=x, y=y)\n",
    "answers = model.predict(X=x)\n",
    "print((answers != y).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, with 0 misclassifications, we must make sure that we are not overfitting with this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.arange(3, 1128, 4)\n",
    "train_idx = np.delete(np.arange(1128), test_idx)\n",
    "\n",
    "x_test = x[test_idx, :]\n",
    "x_train = x[train_idx, :]\n",
    "y_train = np.repeat(train_ans.to_numpy(), 3)\n",
    "y_test = train_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=3, n_estimators=250)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0\n",
      "\n",
      "\n",
      "0.7127659574468085\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X=x_train, y=y_train))\n",
    "print((model.predict(X=x_train) != y_train).sum())\n",
    "print('\\n')\n",
    "print(model.score(X=x_test, y=y_test))\n",
    "print((model.predict(X=x_test) != y_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This disparity in accuracy between the training accuracy and test accuracy confirms that we are overfitting, however our base accuracy of 70% is a bit better than our earlier accuracies of around 65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also thought that the **Logistic Regression** method could be a good fit for this dataset, due to the form of the features a range of numbers rather than specific categories. We implemented it using the SGDClassifier interface from sk-learn with the 'log' loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chain_data = train_data.iloc[:, 4:]\n",
    "x = train_chain_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n",
      "0.7287234042553191\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(penalty='elasticnet', l1_ratio=0.3, alpha=10**-7,\n",
    "                      loss='log', learning_rate='adaptive', eta0=1.25, average=True)\n",
    "model.fit(X=x, y=y)\n",
    "answers = model.predict(X=x)\n",
    "print((answers != y).sum())\n",
    "print(model.score(X=x, y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.arange(3, 1128, 4)\n",
    "train_idx = np.delete(np.arange(1128), test_idx)\n",
    "\n",
    "x_test = x[test_idx, :]\n",
    "x_train = x[train_idx, :]\n",
    "y_train = np.repeat(train_ans.to_numpy(), 3)\n",
    "y_test = train_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-07, average=True, eta0=1.25, l1_ratio=0.3,\n",
       "              learning_rate='adaptive', loss='log', penalty='elasticnet')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7269503546099291\n",
      "231\n",
      "\n",
      "\n",
      "0.7127659574468085\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X=x_train, y=y_train))\n",
    "print((model.predict(X=x_train) != y_train).sum())\n",
    "print('\\n')\n",
    "print(model.score(X=x_test, y=y_test))\n",
    "print((model.predict(X=x_test) != y_test).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
